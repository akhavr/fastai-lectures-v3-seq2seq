{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_12a import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/akhavr/.fastai/data/giga-fren/giga-fren.release2.fixed.en'),\n",
       " PosixPath('/home/akhavr/.fastai/data/giga-fren/models'),\n",
       " PosixPath('/home/akhavr/.fastai/data/giga-fren/cc.fr.300.bin.gz'),\n",
       " PosixPath('/home/akhavr/.fastai/data/giga-fren/cc.fr.300.bin'),\n",
       " PosixPath('/home/akhavr/.fastai/data/giga-fren/data_save.pkl'),\n",
       " PosixPath('/home/akhavr/.fastai/data/giga-fren/cc.en.300.bin'),\n",
       " PosixPath('/home/akhavr/.fastai/data/giga-fren/cc.en.300.bin.gz'),\n",
       " PosixPath('/home/akhavr/.fastai/data/giga-fren/giga-fren.release2.fixed.fr'),\n",
       " PosixPath('/home/akhavr/.fastai/data/giga-fren/questions_easy.csv')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = datasets.Config().data_path()/'giga-fren'\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(path/'giga-fren.release2.fixed.fr') as f: fr = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(path/'giga-fren.release2.fixed.en') as f: en = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re_eq = re.compile('^(Wh[^?.!]+\\?)')\n",
    "# re_fq = re.compile('^([^?.!]+\\?)')\n",
    "# en_fname = path/'giga-fren.release2.fixed.en'\n",
    "# fr_fname = path/'giga-fren.release2.fixed.fr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines = ((re_eq.search(eq), re_fq.search(fq)) \n",
    "#         for eq, fq in zip(open(en_fname, encoding='utf-8'), open(fr_fname, encoding='utf-8')))\n",
    "# qs = [(e.group(), f.group()) for e,f in lines if e and f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qs = [(q1,q2) for q1,q2 in qs]\n",
    "# df = pd.DataFrame({'fr': [q[1] for q in qs], 'en': [q[0] for q in qs]}, columns = ['en', 'fr'])\n",
    "# df.to_csv(path/'questions_easy.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/akhavr/.fastai/data/giga-fren/giga-fren.release2.fixed.en'),\n",
       " PosixPath('/home/akhavr/.fastai/data/giga-fren/models'),\n",
       " PosixPath('/home/akhavr/.fastai/data/giga-fren/cc.fr.300.bin.gz'),\n",
       " PosixPath('/home/akhavr/.fastai/data/giga-fren/cc.fr.300.bin'),\n",
       " PosixPath('/home/akhavr/.fastai/data/giga-fren/data_save.pkl'),\n",
       " PosixPath('/home/akhavr/.fastai/data/giga-fren/cc.en.300.bin'),\n",
       " PosixPath('/home/akhavr/.fastai/data/giga-fren/cc.en.300.bin.gz'),\n",
       " PosixPath('/home/akhavr/.fastai/data/giga-fren/giga-fren.release2.fixed.fr'),\n",
       " PosixPath('/home/akhavr/.fastai/data/giga-fren/questions_easy.csv')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>What is light ?</td>\n",
       "      <td>Qu’est-ce que la lumière?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Who are we?</td>\n",
       "      <td>Où sommes-nous?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Where did we come from?</td>\n",
       "      <td>D'où venons-nous?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>What would we do without it?</td>\n",
       "      <td>Que ferions-nous sans elle ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>What is the absolute location (latitude and lo...</td>\n",
       "      <td>Quelle sont les coordonnées (latitude et longi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  en  \\\n",
       "0                                    What is light ?   \n",
       "1                                        Who are we?   \n",
       "2                            Where did we come from?   \n",
       "3                       What would we do without it?   \n",
       "4  What is the absolute location (latitude and lo...   \n",
       "\n",
       "                                                  fr  \n",
       "0                          Qu’est-ce que la lumière?  \n",
       "1                                    Où sommes-nous?  \n",
       "2                                  D'où venons-nous?  \n",
       "3                       Que ferions-nous sans elle ?  \n",
       "4  Quelle sont les coordonnées (latitude et longi...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/'questions_easy.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['en'] = df['en'].apply(lambda x:x.lower())\n",
    "df['fr'] = df['fr'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "il = ItemList(df.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52331, 52331)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(il), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what is light ?', 'qu’est-ce que la lumière?']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "il[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SplitData\n",
       "Train: ItemList (47068 items)\n",
       "[['who are we?', 'où sommes-nous?'], ['what would we do without it?', 'que ferions-nous sans elle ?'], ['what is the absolute location (latitude and longitude) of badger, newfoundland and labrador?', 'quelle sont les coordonnées (latitude et longitude) de badger, à terre-neuve-etlabrador?'], ['what is the major aboriginal group on vancouver island?', 'quel est le groupe autochtone principal sur l’île de vancouver?'], ['what are the advantages and disadvantages of using an online atlas versus a paper atlas?', 'quels sont les avantages et les désavantages d’utiliser un atlas en ligne comparativement à un atlas en copie papier?'], ['what types of land cover are associated with the colours below?', 'à quel type de couverture des terres associez-vous les couleurs ci-dessous?'], ['what is the population of canada?', 'quelle est la population du canada ?'], ['which province is the most populated?', 'quelle est la province la plus peuplée ?'], ['which province has the highest population density?', 'quelle est la province ayant la plus forte densité de population ?'], ['which province is the least populated?', 'quelle est la province la moins peuplée ?']...]\n",
       "Path: .\n",
       "Valid: ItemList (5263 items)\n",
       "[['what is light ?', 'qu’est-ce que la lumière?'], ['where did we come from?', \"d'où venons-nous?\"], ['which territory is the least populated?', 'quelle est le territoire le moins peuplé ?'], ['what is the population of aboriginal people in canada?', 'quelle est la population autochtone au canada ?'], ['what percentage of the canadian population is male?', 'quel est le pourcentage d’hommes au sein de la population canadienne?'], ['why?', 'pourquoi?'], ['who sets the standards?', 'qui détermine les normes de l’industrie?'], ['what type of frozen (or other) products are you seeking?', 'quels types de produits surgelés ou autres recherchez-vous?'], ['what will happen if a shipment arrives at the border and this information has not been provided?', 'que se passera-t-il si un envoi arrive b la frontipre et que les renseignements n’ont pas été communiqués?'], ['which target market(s)?', 'quel(s) marché(s) cibler?']...]\n",
       "Path: ."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd = SplitData.split_by_func(il, partial(random_splitter, p_valid=0.1))\n",
    "sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what is light ?', 'qu’est-ce que la lumière?']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd.train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetterProcessor(Processor):\n",
    "    def __init__(self, idx): self.idx = idx\n",
    "    def __call__(self, items):\n",
    "        return [i[self.idx] for i in items]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have to create another processor, that would return `x` or `y` from the list of translation pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_proc_tok, en_proc_num = TokenizeProcessor(max_workers=8),NumericalizeProcessor()\n",
    "fr_proc_tok, fr_proc_num = TokenizeProcessor(max_workers=8),NumericalizeProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='24' class='' max='24', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [24/24 00:10<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='24' class='' max='24', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [24/24 00:08<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3' class='' max='3', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:01<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3' class='' max='3', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:01<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ll = label_by_func(sd, lambda x:x, \n",
    "                   proc_x=[GetterProcessor(1), fr_proc_tok, fr_proc_num],\n",
    "                   proc_y=[GetterProcessor(0), en_proc_tok, en_proc_num], \n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11241, 16429)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_proc_num.vocab), len(fr_proc_num.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SplitData\n",
       "Train: LabeledData\n",
       "x: ItemList (904 items)\n",
       "[[2, 63, 9, 20, 17, 12, 0, 8, 3], [2, 45, 375, 9, 57, 8, 3], [2, 0, 0, 9, 57, 8, 3], [2, 17, 0, 9, 57, 539, 50, 8, 3], [2, 37, 14, 11, 0, 78, 0, 18, 0, 71, 10, 0, 25, 19, 0, 9, 0, 9, 0, 8, 3], [2, 34, 16, 13, 540, 140, 541, 41, 0, 10, 0, 8, 3], [2, 23, 14, 11, 108, 18, 11, 0, 0, 38, 542, 26, 240, 0, 19, 38, 542, 26, 0, 0, 8, 3], [2, 19, 34, 153, 10, 543, 22, 0, 0, 9, 40, 11, 0, 376, 9, 0, 8, 3], [2, 37, 16, 12, 141, 21, 35, 8, 3], [2, 37, 16, 12, 154, 12, 46, 544, 8, 3]...]\n",
       "Path: .\n",
       "y: ItemList (904 items)\n",
       "[[2, 9, 11, 0, 8, 3], [2, 20, 14, 47, 8, 3], [2, 26, 119, 47, 472, 63, 8, 3], [2, 9, 50, 47, 18, 473, 39, 8, 3], [2, 9, 11, 10, 474, 188, 75, 0, 15, 0, 69, 12, 0, 23, 0, 15, 0, 8, 3], [2, 9, 11, 10, 475, 110, 476, 51, 0, 0, 8, 3], [2, 9, 14, 10, 217, 15, 0, 12, 327, 42, 189, 477, 478, 16, 0, 477, 8, 3], [2, 9, 138, 12, 0, 328, 14, 0, 54, 10, 0, 0, 8, 3], [2, 9, 11, 10, 159, 12, 27, 8, 3], [2, 48, 218, 11, 10, 89, 329, 8, 3]...]\n",
       "Path: .\n",
       "\n",
       "Valid: LabeledData\n",
       "x: ItemList (96 items)\n",
       "[[2, 23, 26, 14, 11, 108, 28, 13, 215, 8, 3], [2, 23, 423, 11, 114, 646, 0, 28, 0, 12, 0, 21, 35, 42, 13, 0, 0, 18, 28, 0, 146, 156, 18, 119, 8, 3], [2, 23, 156, 66, 0, 292, 30, 0, 0, 8, 3], [2, 27, 290, 9, 33, 81, 30, 558, 21, 35, 8, 3], [2, 23, 99, 10, 156, 0, 39, 114, 0, 9, 40, 8, 3], [2, 31, 9, 20, 15, 66, 0, 292, 41, 20, 90, 8, 3], [2, 17, 0, 9, 40, 8, 3], [2, 27, 0, 36, 576, 26, 296, 577, 8, 3], [2, 75, 53, 9, 33, 49, 36, 60, 10, 321, 0, 10, 203, 10, 12, 0, 8, 3], [2, 33, 0, 22, 76, 41, 11, 567, 0, 45, 53, 9, 33, 26, 72, 8, 3]...]\n",
       "Path: .\n",
       "y: ItemList (96 items)\n",
       "[[2, 9, 36, 21, 39, 17, 10, 227, 8, 3], [2, 9, 95, 635, 237, 50, 25, 0, 13, 0, 27, 64, 0, 21, 10, 0, 15, 605, 44, 345, 163, 160, 8, 3], [2, 9, 345, 18, 423, 84, 0, 8, 3], [2, 22, 28, 19, 25, 21, 10, 66, 341, 8, 3], [2, 9, 112, 12, 0, 75, 34, 95, 69, 345, 14, 30, 225, 8, 3], [2, 9, 35, 499, 21, 10, 85, 8, 3], [2, 9, 50, 30, 67, 8, 3], [2, 22, 0, 16, 0, 21, 349, 350, 8, 3], [2, 26, 24, 19, 53, 41, 38, 562, 0, 21, 66, 110, 375, 8, 3], [2, 26, 24, 19, 53, 599, 8, 3]...]\n",
       "Path: .\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_collate(samples, pad_idx=1, pad_first=True, backwards=False):\n",
    "    \"Function that collect samples and adds padding. Flips token order if needed\"\n",
    "    max_len_x,max_len_y = max([len(s[0]) for s in samples]),max([len(s[1]) for s in samples])\n",
    "    res_x = torch.zeros(len(samples), max_len_x).long() + pad_idx\n",
    "    res_y = torch.zeros(len(samples), max_len_y).long() + pad_idx\n",
    "    if backwards: pad_first = not pad_first\n",
    "    for i,s in enumerate(samples):\n",
    "        if pad_first: \n",
    "            res_x[i,-len(s[0]):],res_y[i,-len(s[1]):] = LongTensor(s[0]),LongTensor(s[1])\n",
    "        else:         \n",
    "            res_x[i,:len(s[0]):],res_y[i,:len(s[1]):] = LongTensor(s[0]),LongTensor(s[1])\n",
    "    if backwards: res_x,res_y = res_x.flip(1),res_y.flip(1)\n",
    "    return res_x,res_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s2s_dls(train_ds, valid_ds, bs, **kwargs):\n",
    "    train_sampler = SortishSampler(train_ds.x, key=lambda t: len(train_ds.x[t]), bs=bs)\n",
    "    valid_sampler = SortSampler(valid_ds.x, key=lambda t: len(valid_ds.x[t]))\n",
    "    return (DataLoader(train_ds, batch_size=bs, sampler=train_sampler,\n",
    "                       collate_fn=seq2seq_collate, **kwargs),\n",
    "            DataLoader(valid_ds, batch_size=bs*2, sampler=valid_sampler, \n",
    "                       collate_fn=seq2seq_collate, **kwargs))\n",
    "\n",
    "def s2s_databunchify(sd, bs, **kwargs):\n",
    "    return DataBunch(*get_s2s_dls(sd.train, sd.valid, bs, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 32\n",
    "data = s2s_databunchify(ll, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2, 61, 642, 10, 57, 8, 3], [2, 24, 15, 48, 8, 3])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter_ds = iter(data.train_ds)\n",
    "x1, y1 = next(iter_ds)\n",
    "x1, y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2, 18, 9803, 10, 57, 260, 47, 8, 3], [2, 10, 44, 48, 20, 479, 42, 8, 3])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1, y1 = next(iter_ds)\n",
    "x1, y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11241"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab = ll.train.proc_y[-1].vocab\n",
    "en_vocab_sz = len(en_vocab)\n",
    "en_vocab_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16429"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_vocab = ll.train.proc_x[-1].vocab\n",
    "fr_vocab_sz = len(fr_vocab)\n",
    "fr_vocab_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok_pad = en_vocab.index(PAD)\n",
    "fr_tok_pad = fr_vocab.index(PAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fr_vecs = ft.load_model(str((path/'cc.fr.300.bin')))\n",
    "en_vecs = ft.load_model(str((path/'cc.en.300.bin')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb(vecs, itos, em_sz=300, mult=1., padding_idx=1):\n",
    "    emb = nn.Embedding(len(itos), em_sz, padding_idx=padding_idx)\n",
    "    wgts = emb.weight.data\n",
    "    vec_dic = {w:vecs.get_word_vector(w) for w in vecs.get_words()}\n",
    "    miss = []\n",
    "    for i,w in enumerate(itos):\n",
    "        try: wgts[i] = tensor(vec_dic[w])\n",
    "        except: miss.append(w)\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11241, 11241, 16429, 16429)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_dec = create_emb(en_vecs, en_proc_num.vocab, padding_idx=en_tok_pad)\n",
    "emb_enc = create_emb(fr_vecs, fr_proc_num.vocab, padding_idx=fr_tok_pad)\n",
    "len(en_proc_num.vocab), en_vocab_sz, len(fr_proc_num.vocab), fr_vocab_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16429, 300]), torch.Size([11241, 300]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_enc.weight.size(), emb_dec.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqRNN(nn.Module):\n",
    "    def __init__(self, emb_enc, emb_dec, \n",
    "                    nh, out_sl, \n",
    "                    nl=2, bos_idx=0, pad_idx=1):\n",
    "        super().__init__()\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
    "        self.bos_idx,self.pad_idx = bos_idx,pad_idx\n",
    "        self.em_sz_enc = emb_enc.embedding_dim\n",
    "        self.em_sz_dec = emb_dec.embedding_dim\n",
    "        self.voc_sz_dec = emb_dec.num_embeddings\n",
    "                 \n",
    "        self.emb_enc = emb_enc\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.gru_enc = nn.GRU(self.em_sz_enc, nh, num_layers=nl,\n",
    "                              dropout=0.25, batch_first=True)\n",
    "        self.out_enc = nn.Linear(nh, self.em_sz_dec, bias=False)\n",
    "        \n",
    "        self.emb_dec = emb_dec\n",
    "        self.gru_dec = nn.GRU(self.em_sz_dec, self.em_sz_dec, num_layers=nl,\n",
    "                              dropout=0.1, batch_first=True)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(self.em_sz_dec, self.voc_sz_dec)\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "        \n",
    "    def encoder(self, bs, inp):\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        _, h = self.gru_enc(emb, h)\n",
    "        h = self.out_enc(h)\n",
    "        return h\n",
    "    \n",
    "    def decoder(self, dec_inp, h):\n",
    "        emb = self.emb_dec(dec_inp).unsqueeze(1)\n",
    "        outp, h = self.gru_dec(emb, h)\n",
    "        outp = self.out(self.out_drop(outp[:,0]))\n",
    "        return h, outp\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        bs, sl = inp.size()\n",
    "        h = self.encoder(bs, inp)\n",
    "        dec_inp = inp.new_zeros(bs).long() + self.bos_idx\n",
    "        \n",
    "        res = []\n",
    "        for i in range(self.out_sl):\n",
    "            h, outp = self.decoder(dec_inp, h)\n",
    "            dec_inp = outp.max(1)[1]\n",
    "            res.append(outp)\n",
    "            if (dec_inp==self.pad_idx).all(): break\n",
    "        return torch.stack(res, dim=1)\n",
    "    \n",
    "    def initHidden(self, bs): \n",
    "        return next(self.parameters()).new_zeros(self.nl, bs, self.nh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16429, 300]), torch.Size([11241, 300]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_sz, nh, nl = 300, 256, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2SeqRNN(emb_enc, emb_dec, nh, nl=nl, out_sl=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 59])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter_dl = iter(data.train_dl)\n",
    "x, y = next(iter_dl)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 772)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model.cuda()((x.cuda()))\n",
    "_, out_len, vs = out.size()\n",
    "out_len, vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_acc(out, targ, pad_idx=1):\n",
    "    bs,targ_len = targ.size()\n",
    "    _,out_len,vs = out.size()\n",
    "    if targ_len>out_len: out  = F.pad(out,  (0,0,0,targ_len-out_len,0,0), value=pad_idx)\n",
    "    if out_len>targ_len: targ = F.pad(targ, (0,out_len-targ_len,0,0), value=pad_idx)\n",
    "    out = out.argmax(2)\n",
    "    return (out==targ).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs = [partial(AvgStatsCallback,seq2seq_acc),\n",
    "       CudaCallback, \n",
    "       Recorder,\n",
    "       partial(GradientClipping, clip=0.1),\n",
    "       #partial(RNNTrainer, α=2., β=1.),\n",
    "       ProgressCallback\n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.layers import CrossEntropyFlat\n",
    "\n",
    "def seq2seq_loss(out, targ, pad_idx=1):\n",
    "    bs,targ_len = targ.size()\n",
    "    _, out_len,vs = out.size()\n",
    "    if targ_len>out_len: \n",
    "        out  = F.pad(out,  (0,0,0,targ_len-out_len,0,0), value=pad_idx)\n",
    "    if out_len>targ_len: \n",
    "        targ = F.pad(targ, (0,out_len-targ_len,0,0), value=pad_idx)\n",
    "    return CrossEntropyFlat()(out, targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(model, data, \n",
    "                seq2seq_loss, \n",
    "                lr=5e-3, \n",
    "                cb_funcs=cbs, \n",
    "                opt_func=adam_opt())\n",
    "clean_learn = Learner(clean_model, data, \n",
    "                    seq2seq_loss, \n",
    "                    lr=5e-3, \n",
    "                    cb_funcs=cbs, \n",
    "                    opt_func=adam_opt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "sched_lr  = combine_scheds([0.3,0.7], cos_1cycle_anneal(lr/10., lr, lr/1e5))\n",
    "sched_mom = combine_scheds([0.3,0.7], cos_1cycle_anneal(0.8, 0.7, 0.8))\n",
    "cbsched = [ParamScheduler('lr', sched_lr), ParamScheduler('mom', sched_mom)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_seq2seq_acc</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_seq2seq_acc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8.333026</td>\n",
       "      <td>0.086364</td>\n",
       "      <td>8.916002</td>\n",
       "      <td>0.043529</td>\n",
       "      <td>05:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(1, cbs=cbsched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(model, data, \n",
    "                seq2seq_loss, \n",
    "                lr=1e-4, \n",
    "                cb_funcs=[LR_Find, Recorder, CudaCallback, ProgressCallback],\n",
    "                opt_func=adam_opt())\n",
    "learn.fit(1)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "learn = Learner(model, data, \n",
    "                seq2seq_loss, \n",
    "                lr=lr, \n",
    "                cb_funcs=cbs, \n",
    "                opt_func=adam_opt())\n",
    "sched_lr  = combine_scheds([0.3,0.7], cos_1cycle_anneal(lr/10., lr, lr/1e5))\n",
    "sched_mom = combine_scheds([0.3,0.7], cos_1cycle_anneal(0.8, 0.7, 0.8))\n",
    "cbsched = [ParamScheduler('lr', sched_lr), ParamScheduler('mom', sched_mom)]\n",
    "\n",
    "learn.fit(4, cbs=cbsched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "model = Seq2SeqRNN(emb_enc, emb_dec, nh, nl=nl, out_sl=30)\n",
    "learn = Learner(model, data, \n",
    "                seq2seq_loss, \n",
    "                lr=lr, \n",
    "                cb_funcs=cbs, \n",
    "                opt_func=adam_opt())\n",
    "sched_lr  = combine_scheds([0.3,0.7], cos_1cycle_anneal(lr/10., lr, lr/1e5))\n",
    "sched_mom = combine_scheds([0.3,0.7], cos_1cycle_anneal(0.8, 0.7, 0.8))\n",
    "cbsched = [ParamScheduler('lr', sched_lr), ParamScheduler('mom', sched_mom)]\n",
    "\n",
    "learn.fit(4, cbs=cbsched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RNNTrainer(Callback):\n",
    "    def __init__(self, α, β): self.α,self.β = α,β\n",
    "    \n",
    "    def after_pred(self):\n",
    "        #Save the extra outputs for later and only returns the true output.\n",
    "        self.raw_out = self.pred\n",
    "    \n",
    "    def after_loss(self):\n",
    "        #AR and TAR\n",
    "        if self.α != 0.:  \n",
    "            self.run.loss += self.α * self.raw_out[2][-1].float().pow(2).mean()\n",
    "        if self.β != 0.:\n",
    "            h = self.raw_out[-1]\n",
    "            if len(h)>1: self.run.loss += self.β * (h[:,1:] - h[:,:-1]).float().pow(2).mean()\n",
    "                \n",
    "    def begin_epoch(self):\n",
    "        #Shuffle the texts at the beginning of the epoch\n",
    "        if hasattr(self.dl.dataset, \"batchify\"): self.dl.dataset.batchify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs = [partial(AvgStatsCallback,seq2seq_acc),\n",
    "       CudaCallback, \n",
    "       Recorder,\n",
    "       partial(GradientClipping, clip=0.1),\n",
    "       partial(RNNTrainer, α=2., β=1.),\n",
    "       ProgressCallback\n",
    "      ]\n",
    "lr = 5e-3\n",
    "learn = Learner(model, data, \n",
    "                seq2seq_loss, \n",
    "                lr=lr, \n",
    "                cb_funcs=cbs, \n",
    "                opt_func=adam_opt())\n",
    "sched_lr  = combine_scheds([0.3,0.7], cos_1cycle_anneal(lr/10., lr, lr/1e5))\n",
    "sched_mom = combine_scheds([0.3,0.7], cos_1cycle_anneal(0.8, 0.7, 0.8))\n",
    "cbsched = [ParamScheduler('lr', sched_lr), ParamScheduler('mom', sched_mom)]\n",
    "learn.fit(1, cbs=cbsched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(model, data, \n",
    "                seq2seq_loss, \n",
    "                lr=1e-4, \n",
    "                cb_funcs=[LR_Find, Recorder, CudaCallback, ProgressCallback],\n",
    "                opt_func=adam_opt())\n",
    "learn.fit(1)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGram():\n",
    "    def __init__(self, ngram, max_n=5000): self.ngram,self.max_n = ngram,max_n\n",
    "    def __eq__(self, other):\n",
    "        if len(self.ngram) != len(other.ngram): return False\n",
    "        return np.all(np.array(self.ngram) == np.array(other.ngram))\n",
    "    def __hash__(self): return int(sum([o * self.max_n**i for i,o in enumerate(self.ngram)]))\n",
    "    \n",
    "def get_grams(x, n, max_n=5000):\n",
    "    return x if n==1 else [NGram(x[i:i+n], max_n=max_n) for i in range(len(x)-n+1)]\n",
    "\n",
    "def get_correct_ngrams(pred, targ, n, max_n=5000):\n",
    "    pred_grams,targ_grams = get_grams(pred, n, max_n=max_n),get_grams(targ, n, max_n=max_n)\n",
    "    pred_cnt,targ_cnt = Counter(pred_grams),Counter(targ_grams)\n",
    "    return sum([min(c, targ_cnt[g]) for g,c in pred_cnt.items()]),len(pred_grams)\n",
    "\n",
    "class BleuCallback(Callback):\n",
    "    def __init__(self, vocab_sz):\n",
    "        self.vocab_sz = vocab_sz\n",
    "    \n",
    "    def begin_epoch(self):\n",
    "        self.pred_len,self.targ_len,self.corrects,self.counts = 0,0,[0]*4,[0]*4\n",
    "    \n",
    "    def after_batch(self):\n",
    "        last_output = self.run.pred.argmax(dim=-1)\n",
    "        last_target = self.run.yb\n",
    "        for pred,targ in zip(last_output.cpu().numpy(),last_target.cpu().numpy()):\n",
    "            self.pred_len += len(pred)\n",
    "            self.targ_len += len(targ)\n",
    "            for i in range(4):\n",
    "                c,t = get_correct_ngrams(pred, targ, i+1, max_n=self.vocab_sz)\n",
    "                self.corrects[i] += c\n",
    "                self.counts[i]   += t\n",
    "    \n",
    "    def after_epoch(self):\n",
    "        precs = [c/t for c,t in zip(self.corrects,self.counts)]\n",
    "        len_penalty = np.exp(1 - self.targ_len/self.pred_len) if self.pred_len < self.targ_len else 1\n",
    "        bleu = len_penalty * ((precs[0]*precs[1]*precs[2]*precs[3]) ** 0.25)\n",
    "        return print(bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs = [partial(AvgStatsCallback, seq2seq_acc),\n",
    "       CudaCallback, \n",
    "       Recorder,\n",
    "       partial(GradientClipping, clip=0.1),\n",
    "       partial(RNNTrainer, α=2., β=1.),\n",
    "       ProgressCallback\n",
    "      ]\n",
    "lr = 5e-3\n",
    "learn = Learner(model, data, \n",
    "                seq2seq_loss, \n",
    "                lr=lr, \n",
    "                cbs = [BleuCallback(fr_vocab_sz),],\n",
    "                cb_funcs=cbs, \n",
    "                opt_func=adam_opt())\n",
    "sched_lr  = combine_scheds([0.3,0.7], cos_1cycle_anneal(lr/10., lr, lr/1e5))\n",
    "sched_mom = combine_scheds([0.3,0.7], cos_1cycle_anneal(0.8, 0.7, 0.8))\n",
    "cbsched = [ParamScheduler('lr', sched_lr), ParamScheduler('mom', sched_mom)]\n",
    "learn.fit(1, cbs=cbsched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, cbs=cbsched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(learn):\n",
    "    learn.model.eval()\n",
    "    inputs, targets, outputs = [],[],[]\n",
    "    with torch.no_grad():\n",
    "        for xb,yb in progress_bar(learn.dl):\n",
    "            out = learn.model(xb.cuda())\n",
    "            for x,y,z in zip(xb,yb,out):\n",
    "                inputs.append([e for e in en_proc_num.deproc1(x) if e!='xxpad'])\n",
    "                targets.append([e for e in fr_proc_num.deproc1(y) if e!='xxpad'])\n",
    "                outputs.append([e for e in fr_proc_num.deproc1(z.argmax(1)) if e!='xxpad'])\n",
    "    return inputs, targets, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets, outputs = get_predictions(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "il[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' '.join(inputs[1]))\n",
    "print('--')\n",
    "print(' '.join(targets[1]))\n",
    "print('--')\n",
    "print(' '.join(outputs[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
